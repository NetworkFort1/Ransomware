{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7eecb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scapy.all import *\n",
    "from ipaddress import ip_address\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statistics import median, stdev, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d068b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_session(session_packets):\n",
    "    session_length = len(session_packets)\n",
    "    total_packet_length = sum(len(pkt) for pkt in session_packets)\n",
    "    total_payload_size = sum(len(pkt.payload) for pkt in session_packets)\n",
    "    start_time = session_packets[0].time\n",
    "    end_time = session_packets[-1].time\n",
    "    \n",
    "    # Initialize default values for features\n",
    "    protocol_type = None\n",
    "    src_ip = None\n",
    "    dst_ip = None\n",
    "    src_port = None\n",
    "    dst_port = None\n",
    "    flags = None\n",
    "    \n",
    "    # IPv4 features\n",
    "    version_ipv4 = None\n",
    "    ihl_ipv4 = None\n",
    "    type_of_service_ipv4 = None\n",
    "    total_length_ipv4 = None\n",
    "    identification_ipv4 = None\n",
    "    fragment_offset_ipv4 = None\n",
    "    ttl_ipv4 = None\n",
    "    header_checksum_ipv4 = None\n",
    "    options_ipv4 = None\n",
    "    \n",
    "    # IPv6 features\n",
    "    version_ipv6 = None\n",
    "    traffic_class_ipv6 = None\n",
    "    flow_label_ipv6 = None\n",
    "    payload_length_ipv6 = None\n",
    "    next_header_ipv6 = None\n",
    "    hop_limit_ipv6 = None\n",
    "    \n",
    "    # Payload-level features\n",
    "    payload_lengths = [len(pkt.payload) for pkt in session_packets]\n",
    "    mean_payload_length = sum(payload_lengths) / len(payload_lengths)\n",
    "    median_payload_length = median(payload_lengths)\n",
    "    max_payload_length = max(payload_lengths)\n",
    "    min_payload_length = min(payload_lengths)\n",
    "    std_payload_length = stdev(payload_lengths) if len(payload_lengths) > 1 else 0  # Avoid division by zero\n",
    "    var_payload_length = variance(payload_lengths) if len(payload_lengths) > 1 else 0  # Avoid division by zero\n",
    "    \n",
    "    # Extract features from the packet in the session\n",
    "    first_pkt = session_packets[0]\n",
    "    if IP in first_pkt:\n",
    "        protocol_type = first_pkt[IP].proto\n",
    "        src_ip = int(ip_address(first_pkt[IP].src))\n",
    "        dst_ip = int(ip_address(first_pkt[IP].dst))\n",
    "        \n",
    "        # Extract IPv4 header features\n",
    "        version_ipv4 = first_pkt[IP].version\n",
    "        ihl_ipv4 = first_pkt[IP].ihl\n",
    "        type_of_service_ipv4 = first_pkt[IP].tos\n",
    "        total_length_ipv4 = first_pkt[IP].len\n",
    "        identification_ipv4 = first_pkt[IP].id\n",
    "        fragment_offset_ipv4 = first_pkt[IP].frag\n",
    "        ttl_ipv4 = first_pkt[IP].ttl\n",
    "        header_checksum_ipv4 = first_pkt[IP].chksum\n",
    "        options_ipv4 = first_pkt[IP].options if first_pkt[IP].options else None\n",
    "    \n",
    "    if IPv6 in first_pkt:\n",
    "        protocol_type = 6  # IPv6 protocol type\n",
    "        src_ip = first_pkt[IPv6].src\n",
    "        dst_ip = first_pkt[IPv6].dst\n",
    "        \n",
    "        # Extract IPv6 header features\n",
    "        version_ipv6 = first_pkt[IPv6].version\n",
    "        traffic_class_ipv6 = first_pkt[IPv6].tc\n",
    "        flow_label_ipv6 = first_pkt[IPv6].fl\n",
    "        payload_length_ipv6 = first_pkt[IPv6].plen\n",
    "        next_header_ipv6 = first_pkt[IPv6].nh\n",
    "        hop_limit_ipv6 = first_pkt[IPv6].hlim\n",
    "    \n",
    "    if TCP in first_pkt:\n",
    "        src_port = first_pkt[TCP].sport\n",
    "        dst_port = first_pkt[TCP].dport\n",
    "        flags = first_pkt[TCP].flags\n",
    "    elif UDP in first_pkt:\n",
    "        src_port = first_pkt[UDP].sport\n",
    "        dst_port = first_pkt[UDP].dport\n",
    "    \n",
    "    # Create a dictionary of features\n",
    "    features = {\n",
    "        'session_length': session_length,\n",
    "        'total_packet_length': total_packet_length,\n",
    "        'total_payload_size': total_payload_size,\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time,\n",
    "        'protocol_type': protocol_type,\n",
    "        'src_ip': src_ip,\n",
    "        'dst_ip': dst_ip,\n",
    "        'src_port': src_port,\n",
    "        'dst_port': dst_port,\n",
    "        'flags': flags,\n",
    "        # IPv4 features\n",
    "        'version_ipv4': version_ipv4,\n",
    "        'ihl_ipv4': ihl_ipv4,\n",
    "        'type_of_service_ipv4': type_of_service_ipv4,\n",
    "        'total_length_ipv4': total_length_ipv4,\n",
    "        'identification_ipv4': identification_ipv4,\n",
    "        'fragment_offset_ipv4': fragment_offset_ipv4,\n",
    "        'ttl_ipv4': ttl_ipv4,\n",
    "        'header_checksum_ipv4': header_checksum_ipv4,\n",
    "        'options_ipv4': options_ipv4,\n",
    "        # IPv6 features\n",
    "        'version_ipv6': version_ipv6,\n",
    "        'traffic_class_ipv6': traffic_class_ipv6,\n",
    "        'flow_label_ipv6': flow_label_ipv6,\n",
    "        'payload_length_ipv6': payload_length_ipv6,\n",
    "        'next_header_ipv6': next_header_ipv6,\n",
    "        'hop_limit_ipv6': hop_limit_ipv6,\n",
    "        # Payload-level features\n",
    "        'mean_payload_length': mean_payload_length,\n",
    "        'median_payload_length': median_payload_length,\n",
    "        'max_payload_length': max_payload_length,\n",
    "        'min_payload_length': min_payload_length,\n",
    "        'std_payload_length': std_payload_length,\n",
    "        'var_payload_length': var_payload_length\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc69a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_folder(folder_path):\n",
    "    all_features = []\n",
    "    pcap_files = [f for f in os.listdir(folder_path) if f.endswith('.pcap') or f.endswith('.pcapng') or f.endswith('.cap')]\n",
    "    for pcap_file in pcap_files:\n",
    "        pcap_file_path = os.path.join(folder_path, pcap_file)\n",
    "        packets = rdpcap(pcap_file_path)\n",
    "        \n",
    "        sessions = packets.sessions()  # Group packets into sessions\n",
    "        \n",
    "        for session_key in sessions:\n",
    "            session_packets = sessions[session_key]\n",
    "            features = extract_features_from_session(session_packets)\n",
    "            all_features.append(features)\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65f9b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the 'attack' and 'normal' folders\n",
    "attack_folder = 'attack'\n",
    "normal_folder = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95c605f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from 'attack' folder\n",
    "attack_features = extract_features_from_folder(attack_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e937f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from 'normal' folder\n",
    "normal_features = extract_features_from_folder(normal_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57addcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to DataFrame\n",
    "attack_df = pd.DataFrame(attack_features)\n",
    "normal_df = pd.DataFrame(normal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52ab4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to the DataFrames\n",
    "attack_df['label'] = 'attack'\n",
    "normal_df['label'] = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ffc09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate attack and normal DataFrames\n",
    "combined_df = pd.concat([attack_df, normal_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5044ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame to mix attack and normal data\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63d389c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to seconds\n",
    "combined_df['start_time'] = combined_df['start_time'].astype(int)\n",
    "combined_df['end_time'] = combined_df['end_time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49cf8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the \"flags\" column\n",
    "le = LabelEncoder()\n",
    "combined_df['flags'] = le.fit_transform(combined_df['flags'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "613abffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels\n",
    "X = combined_df.drop('label', axis=1)\n",
    "y = combined_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba2608e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c52dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'options' column exists before preprocessing\n",
    "if 'options' in X_train.columns:\n",
    "    # Preprocess 'options' feature\n",
    "    X_train['options'] = X_train['options'].apply(lambda x: str(x))\n",
    "    X_test['options'] = X_test['options'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b68cd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for imputation\n",
    "numeric_cols = X_train.select_dtypes(include=['number']).columns\n",
    "X_train_numeric = X_train[numeric_cols]\n",
    "X_test_numeric = X_test[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "369b9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for numeric columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_numeric)\n",
    "X_test_imputed = imputer.transform(X_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b09c866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "508eab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e35024db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9973941368078176\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf0124c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       0.99      0.99      0.99       199\n",
      "      normal       1.00      1.00      1.00      1336\n",
      "\n",
      "    accuracy                           1.00      1535\n",
      "   macro avg       0.99      1.00      0.99      1535\n",
      "weighted avg       1.00      1.00      1.00      1535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43ccfc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ransomware_rf2.sav']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_classifier, 'ransomware_rf2.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2d7ff",
   "metadata": {},
   "source": [
    "# Test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d94024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of df_imputed: Index(['session_length', 'total_packet_length', 'total_payload_size',\n",
      "       'start_time', 'end_time', 'protocol_type', 'src_port', 'dst_port',\n",
      "       'flags', 'version_ipv4', 'ihl_ipv4', 'type_of_service_ipv4',\n",
      "       'total_length_ipv4', 'identification_ipv4', 'fragment_offset_ipv4',\n",
      "       'ttl_ipv4', 'header_checksum_ipv4', 'version_ipv6',\n",
      "       'traffic_class_ipv6', 'flow_label_ipv6', 'payload_length_ipv6',\n",
      "       'next_header_ipv6', 'hop_limit_ipv6', 'mean_payload_length',\n",
      "       'median_payload_length', 'max_payload_length', 'min_payload_length',\n",
      "       'std_payload_length', 'var_payload_length'],\n",
      "      dtype='object')\n",
      "Shape of df_imputed: (815, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehtisham Awan\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: C:/Users/Ehtisham Awan/Desktop/ransomware ml/testing/smbtorture_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "from scapy.all import *\n",
    "from ipaddress import ip_address\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from statistics import median, stdev, variance\n",
    "\n",
    "# Load the trained model\n",
    "rf_classifier = joblib.load('ransomware_rf2.sav')\n",
    "\n",
    "def extract_features_from_session(session_packets):\n",
    "    session_length = len(session_packets)\n",
    "    total_packet_length = sum(len(pkt) for pkt in session_packets)\n",
    "    total_payload_size = sum(len(pkt.payload) for pkt in session_packets)\n",
    "    start_time = session_packets[0].time\n",
    "    end_time = session_packets[-1].time\n",
    "    \n",
    "    # Initialize default values for features\n",
    "    protocol_type = None\n",
    "    src_ip = None\n",
    "    dst_ip = None\n",
    "    src_port = None\n",
    "    dst_port = None\n",
    "    flags = None\n",
    "    \n",
    "    # IPv4 features\n",
    "    version_ipv4 = None\n",
    "    ihl_ipv4 = None\n",
    "    type_of_service_ipv4 = None\n",
    "    total_length_ipv4 = None\n",
    "    identification_ipv4 = None\n",
    "    fragment_offset_ipv4 = None\n",
    "    ttl_ipv4 = None\n",
    "    header_checksum_ipv4 = None\n",
    "    options_ipv4 = None\n",
    "    \n",
    "    # IPv6 features\n",
    "    version_ipv6 = None\n",
    "    traffic_class_ipv6 = None\n",
    "    flow_label_ipv6 = None\n",
    "    payload_length_ipv6 = None\n",
    "    next_header_ipv6 = None\n",
    "    hop_limit_ipv6 = None\n",
    "    \n",
    "    # Payload-level features\n",
    "    payload_lengths = [len(pkt.payload) for pkt in session_packets]\n",
    "    mean_payload_length = sum(payload_lengths) / len(payload_lengths)\n",
    "    median_payload_length = median(payload_lengths)\n",
    "    max_payload_length = max(payload_lengths)\n",
    "    min_payload_length = min(payload_lengths)\n",
    "    std_payload_length = stdev(payload_lengths) if len(payload_lengths) > 1 else 0  # Avoid division by zero\n",
    "    var_payload_length = variance(payload_lengths) if len(payload_lengths) > 1 else 0  # Avoid division by zero\n",
    "    \n",
    "    # Extract features from the packet in the session\n",
    "    first_pkt = session_packets[0]\n",
    "    if IP in first_pkt:\n",
    "        protocol_type = first_pkt[IP].proto\n",
    "        src_ip = int(ip_address(first_pkt[IP].src))\n",
    "        dst_ip = int(ip_address(first_pkt[IP].dst))\n",
    "        \n",
    "        # Extract IPv4 header features\n",
    "        version_ipv4 = first_pkt[IP].version\n",
    "        ihl_ipv4 = first_pkt[IP].ihl\n",
    "        type_of_service_ipv4 = first_pkt[IP].tos\n",
    "        total_length_ipv4 = first_pkt[IP].len\n",
    "        identification_ipv4 = first_pkt[IP].id\n",
    "        fragment_offset_ipv4 = first_pkt[IP].frag\n",
    "        ttl_ipv4 = first_pkt[IP].ttl\n",
    "        header_checksum_ipv4 = first_pkt[IP].chksum\n",
    "        options_ipv4 = first_pkt[IP].options if first_pkt[IP].options else None\n",
    "    \n",
    "    if IPv6 in first_pkt:\n",
    "        protocol_type = 6  # IPv6 protocol type\n",
    "        src_ip = first_pkt[IPv6].src\n",
    "        dst_ip = first_pkt[IPv6].dst\n",
    "        \n",
    "        # Extract IPv6 header features\n",
    "        version_ipv6 = first_pkt[IPv6].version\n",
    "        traffic_class_ipv6 = first_pkt[IPv6].tc\n",
    "        flow_label_ipv6 = first_pkt[IPv6].fl\n",
    "        payload_length_ipv6 = first_pkt[IPv6].plen\n",
    "        next_header_ipv6 = first_pkt[IPv6].nh\n",
    "        hop_limit_ipv6 = first_pkt[IPv6].hlim\n",
    "    \n",
    "    if TCP in first_pkt:\n",
    "        src_port = first_pkt[TCP].sport\n",
    "        dst_port = first_pkt[TCP].dport\n",
    "        flags = first_pkt[TCP].flags\n",
    "    elif UDP in first_pkt:\n",
    "        src_port = first_pkt[UDP].sport\n",
    "        dst_port = first_pkt[UDP].dport\n",
    "    \n",
    "    # Create a dictionary of features\n",
    "    features = {\n",
    "        'session_length': session_length,\n",
    "        'total_packet_length': total_packet_length,\n",
    "        'total_payload_size': total_payload_size,\n",
    "        'start_time': start_time,\n",
    "        'end_time': end_time,\n",
    "        'protocol_type': protocol_type,\n",
    "        'src_ip': src_ip,\n",
    "        'dst_ip': dst_ip,\n",
    "        'src_port': src_port,\n",
    "        'dst_port': dst_port,\n",
    "        'flags': flags,\n",
    "        # IPv4 features\n",
    "        'version_ipv4': version_ipv4,\n",
    "        'ihl_ipv4': ihl_ipv4,\n",
    "        'type_of_service_ipv4': type_of_service_ipv4,\n",
    "        'total_length_ipv4': total_length_ipv4,\n",
    "        'identification_ipv4': identification_ipv4,\n",
    "        'fragment_offset_ipv4': fragment_offset_ipv4,\n",
    "        'ttl_ipv4': ttl_ipv4,\n",
    "        'header_checksum_ipv4': header_checksum_ipv4,\n",
    "        'options_ipv4': options_ipv4,\n",
    "        # IPv6 features\n",
    "        'version_ipv6': version_ipv6,\n",
    "        'traffic_class_ipv6': traffic_class_ipv6,\n",
    "        'flow_label_ipv6': flow_label_ipv6,\n",
    "        'payload_length_ipv6': payload_length_ipv6,\n",
    "        'next_header_ipv6': next_header_ipv6,\n",
    "        'hop_limit_ipv6': hop_limit_ipv6,\n",
    "        # Payload-level features\n",
    "        'mean_payload_length': mean_payload_length,\n",
    "        'median_payload_length': median_payload_length,\n",
    "        'max_payload_length': max_payload_length,\n",
    "        'min_payload_length': min_payload_length,\n",
    "        'std_payload_length': std_payload_length,\n",
    "        'var_payload_length': var_payload_length\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_features_from_file(file_path):\n",
    "    packets = rdpcap(file_path)\n",
    "    sessions = packets.sessions()\n",
    "    all_features = []\n",
    "    for session_key in sessions:\n",
    "        session_packets = sessions[session_key]\n",
    "        features = extract_features_from_session(session_packets)\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "def browse_files():\n",
    "    filename = filedialog.askopenfilename(initialdir=\"/\", title=\"Select a File\", filetypes=((\"PCAP files\", \"*.pcap *.pcapng *.cap\"), (\"all files\", \"*.*\")))\n",
    "    if filename:\n",
    "        features = extract_features_from_file(filename)\n",
    "        df = pd.DataFrame(features)\n",
    "        df['start_time'] = df['start_time'].astype(int)\n",
    "        df['end_time'] = df['end_time'].astype(int)\n",
    "        if 'flags' in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df['flags'] = le.fit_transform(df['flags'].astype(str))\n",
    "        if 'options' in df.columns:  # Check if 'options' column exists\n",
    "            df['options'] = df['options'].apply(lambda x: str(x))  # Preprocess 'options' feature\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        df_numeric = df[numeric_cols]\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        df_imputed = imputer.fit_transform(df_numeric)\n",
    "        \n",
    "        # Initialize DataFrame with df_imputed and use column names from df_numeric\n",
    "        df_imputed = pd.DataFrame(df_imputed, columns=df_numeric.columns)\n",
    "        \n",
    "        # Print columns of df_imputed for debugging\n",
    "        print(\"Columns of df_imputed:\", df_imputed.columns)\n",
    "        \n",
    "        print(\"Shape of df_imputed:\", df_imputed.shape)\n",
    "        predictions = rf_classifier.predict(df_imputed)\n",
    "        df['prediction'] = predictions\n",
    "        save_path = os.path.splitext(filename)[0] + '_predictions.csv'\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(\"Predictions saved to:\", save_path)\n",
    "\n",
    "# Create the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Ransomware Detection\")\n",
    "root.geometry(\"400x200\")\n",
    "\n",
    "# Create a browse button\n",
    "browse_button = tk.Button(root, text=\"Browse Files\", command=browse_files)\n",
    "browse_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3cceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cfb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
